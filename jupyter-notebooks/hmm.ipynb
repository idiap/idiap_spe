{"cells":[{"cell_type":"markdown","metadata":{},"source":"Introduction to Hidden Markov Models\n====================================\n\n"},{"cell_type":"markdown","metadata":{},"source":["## Preamble\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n%autoreload 2"]},{"cell_type":"markdown","metadata":{},"source":["### Formulas and definitions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   A **Markov chain** or **process** is a sequence of events, usually called\n    **states**, the probability of each of which is dependent only on the\n    event immediately preceding it.\n-   A **hidden Markov model** (HMM) represents stochastic sequences as\n    Markov chains where the states are not directly observed, but are\n    associated with a probability density function (pdf). The generation\n    of a random sequence is then the result of a random walk in the chain\n    (i.e. the browsing of a random sequence of states\n    $Q=\\{q_1,\\cdots q_T\\}$) and of a draw (called an *emission*) at each\n    visit of a state.  \n    The sequence of states, which is the quantity of interest in speech\n    recognition and in most of the other pattern recognition problems, can\n    be observed only *through* the stochastic processes defined into each\n    state (i.e. you must know the parameters of the pdfs of each state\n    before being able to associate a sequence of states\n    $Q=\\{q_1,\\cdots q_T\\}$ to a sequence of observations\n    $X=\\{x_1,\\cdots x_T\\}$). The true sequence of states is therefore\n    *hidden* by a first layer of stochastic processes. HMMs are\n    *dynamic models*, in the sense that they are specifically designed to\n    account for some macroscopic structure of the random sequences. In the\n    previous lab, concerned with *Gaussian Statistics and Statistical\n    Pattern Recognition*, random sequences of observations were considered\n    as the result of a series of *independent* draws in one or several\n    Gaussian densities. To this simple statistical modeling scheme, HMMs\n    add the specification of some *statistical dependence* between the\n    (Gaussian) densities from which the observations are drawn.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Parameters of a HMM\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   The **emission probabilities** are the pdfs that characterize each state\n    $q_i$, i.e. $p(x|q_i)$. To simplify the notations, they will be\n    denoted $b_i(x)$. For practical reasons, they are usually Gaussian or\n    mixtures of Gaussians, but the states could be parameterized in\n    terms of any other kind of pdf (including discrete probabilities and\n    artificial neural networks).\n-   The **transition probabilities** are the probability to go from a state\n    $i$ to a state $j$, i.e. $P(q_j|q_i)$. They are stored in matrices\n    where each term $a_{i,j}$ denotes a probability $P(q_j|q_i)$.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Non-emitting initial and final states\n\n"]},{"cell_type":"markdown","metadata":{},"source":["If a random sequence $X=\\{x_1,\\cdots x_T\\}$ has a finite length $T$, the\nfact that the sequence begins or ends has to be modeled as two\nadditional discrete events. In HMMs, this corresponds to the addition of\ntwo *non-emitting states*, the initial state and the final state. Since\ntheir role is just to model the *start* or *end* events, they are not\nassociated with any emission probabilities.  \nThe transitions starting from the initial state correspond to the\nmodeling of an *initial state distribution* $P(I|q_j)$, which indicates\nthe probability to start the state sequence with the emitting state\n$q_j$.  \nThe final state usually has only one non-null transition that loops onto\nitself with a probability of $1$ (it is an *absorbent state*), so that\nthe state sequence gets \"trapped\" into it when it is reached.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Ergodic versus left-right HMMs\n\n"]},{"cell_type":"markdown","metadata":{},"source":["A HMM allowing for transitions from any emitting state to any other\nemitting state is called an **ergodic HMM**.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from idiap_spe.data.hmm import hmm1, hmm2, hmm3, hmm4, hmm5, hmm6\n\nhmm1.plot()"]},{"cell_type":"markdown","metadata":{},"source":["Alternately, an HMM where the transitions only go from one state to\nitself or to a unique follower is called a **left-right HMM**.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["hmm3.plot()"]},{"cell_type":"markdown","metadata":{},"source":["### Values used throughout the experiments\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The following 2-dimensional Gaussian densities will be used to model\nsimulated vowel observations, where the considered features are the two\nfirst formants. They will be combined into Markov Models that will be\nused to model some observation sequences.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\nfrom idiap_spe.data.hmm import GAUSSIANS\nfor vowel, gaussian in GAUSSIANS.items():\n    print(f\"Gaussian('{vowel}'): {gaussian}\")"]},{"cell_type":"markdown","metadata":{},"source":["Let's look at the resulting HMMs. We represent the initial state $I$ and\nfinal state $F$ with mean and variance of zero, but they don't actually\nemit any observations.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print(hmm1.labels)\nprint(hmm1.transitions)\nfor gaussian in hmm1.gaussians:\n    print(gaussian)"]},{"cell_type":"markdown","metadata":{},"source":["We can also visualise the transition matrix as a graph.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["hmm1.plot()"]},{"cell_type":"markdown","metadata":{},"source":["Here are the remaining HMMs.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["hmm2.pprint()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["hmm3.pprint()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["hmm4.pprint()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["hmm5.pprint()"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["hmm6.pprint()"]},{"cell_type":"markdown","metadata":{},"source":["## Generating samples from HMMs\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Experiment\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Generate a sample $X$ coming from the Hidden Markov Models `hmm1`,\n`hmm2`, `hmm3` and `hmm4`. Use the `HMM.sample()` method to do several\ndraws with each of these models and plot them.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Example\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from idiap_spe.hmm import HMM\nhelp(HMM.sample)"]},{"cell_type":"markdown","metadata":{},"source":["Draw a sample and plot the resulting sequence. The sequence is\nrepresented by a gray line where each point is overlaid with a colored\ndot. The different colors indicate the state from which any particular\ndot has been drawn.\n\nThe lefthand plots highlight the notion of a sequence of states\nassociated with a sequence of observations. The 2-dimensional righthand\nplot highlights the spatial distribution of the observations and also\nshows the Gaussian distributions from which the samples for each state\nwere drawn.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["X, states, labels = hmm1.sample(plot=True)\nprint(X)\nprint(states)\nprint(labels)"]},{"cell_type":"markdown","metadata":{},"source":["Repeat this several times and also draw samples from the other models.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["X, states, labels = hmm4.sample(plot=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Questions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  How can you verify that a transition matrix is valid?\n2.  What is the effect of the different transition matrices on the\n    sequences obtained during the current experiment? Hence, what is the\n    role of the transition probabilities in the Markovian modeling\n    framework?\n3.  What would happen if we didn't have a final state ?\n4.  In the case of HMMs with plain Gaussian emission probabilities, what\n    quantities should be present in the complete parameter set $\\Theta$\n    that specifies a particular model?  \n    If the model is ergodic with $N$ states (including the initial and\n    final), and represents data of dimension $D$, what is the total\n    number of parameters in $\\Theta$?\n5.  Which type of HMM (ergodic or left-right) would you use to model\n    words?\n\n"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":"true"},"source":["### Answers\n\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"answer\" id=\"orge5d2046\">\n<ol class=\"org-ol\">\n<li>In a transition matrix $A$, the element $A_{i,j}$ specifies the\nprobability to go from state $i$ to state $j$. Hence, the values on\nrow $i$ specify the probability of all the possible transitions that\nstart from state $i$. This set of transitions must be a <i>complete set\nof discrete events</i>. Hence, the terms of the $i^{th}$ row of the\nmatrix must sum up to $1$. Similarly, the sum of all the elements of\nthe matrix is equal to the number of states in the HMM.</li>\n</ol>\n\n<div class=\"org-src-container\">\n<pre class=\"src src-python\">def validate_transition_matrix(hmm: HMM) -&gt; bool:\n    \"\"\"Ensure that each row in the transition matrix sums to one.\"\"\"\n    row_sums = np.sum(hmm.transitions, axis=1)\n    return np.allclose(row_sums, np.ones(hmm.n_states))\n\nfor hmm in [hmm1, hmm2, hmm3, hmm4, hmm5, hmm6]:\n    assert validate_transition_matrix(hmm)\n</pre>\n</div>\n\n<ol class=\"org-ol\">\n<li value=\"2\">The transition matrix of <code>hmm1</code> indicates that the probability of\nstaying in a particular state is close to the probability of\ntransiting to another state. Hence, it allows for frequent jumps from\none state to any other state. The observation variable therefore\nfrequently jumps from one phoneme to any other, forming sharply\nchanging sequences like ​<i>a,i,a,y,y,i,a,y,y,$\\ldots$​/.<br />\nAlternately, the transition matrix of <code>hmm2</code> specifies high\nprobabilities of staying in a particular state. Hence, it allows for\nmore \"stable\" sequences, like ​/a,a,a,y,y,y,i,i,i,i,i,y,y,$\\ldots$​/.<br />\nFinally, the transition matrix of <code>hmm4</code> also fixes the order in\nwhich the states are browsed: the given probabilities force the\nobservation variable to go through ​/a​/, then to go through ​/i​/, and\nfinally to stay in ​/y​/, e.g. ​/a,a,a,a,i,i,i,y,y,y,y,$\\ldots$​/.<br />\nHence, the role of the transition probabilities is to /introduce a\ntemporal (or spatial) structure in the modeling of random sequences</i>.<br />\nFurthermore, the obtained sequences have variable lengths: the\ntransition probabilities implicitly model a variability in the duration\nof the sequences. As a matter of fact, different speakers or different\nspeaking conditions introduce a variability in the phoneme or word\ndurations. In this respect, HMMs are particularly well adapted to speech\nmodeling.</li>\n\n<li value=\"3\">If we didn't have a final state, the model would wander from state to\nstate indefinitely, and necessarily correspond to sequences of\ninfinite length.</li>\n</ol>\n\n</div>\n\n<div class=\"answer\" id=\"org954cfc4\">\n<ol class=\"org-ol\">\n<li value=\"4\"><p>\nIn the case of HMMs with Gaussian emission probabilities, the\nparameter set $\\Theta$ comprises,:\n</p>\n\n<ul class=\"org-ul\">\n<li>the transition probabilities $A$;</li>\n<li>the parameters of the Gaussian densities characterizing each state,\ni.e. the means $\\mu_i$ and the variances $\\Sigma_i$.</li>\n</ul>\n\n<p>\nThe initial state distribution is sometimes modeled as an additional\nparameter instead of being represented in the transition matrix.<br />\nIn the case of an ergodic HMM with $N$ emitting states and Gaussian\nemission probabilities, we have:<br />\n</p>\n\n<ul class=\"org-ul\">\n<li>$(N-2) \\times (N-2)$ transitions, plus $(N-2)$ initial state\nprobabilities and $(N-2)$ probabilities to go to the final state;</li>\n<li>$(N-2)$ emitting states where each pdf is characterized by a $D$\ndimensional mean and a $D \\times D$ covariance matrix.</li>\n</ul>\n\n<p>\nHence, in this case, the total number of parameters is\n$(N-2) \\times \\left( N + D \\times (D+1) \\right)$. Note that this number\ngrows exponentially with the number of states and the dimension of the\ndata.\n</p></li>\n\n<li value=\"5\">Words are made of ordered sequences of phonemes: ​/h​/ is followed by\n​/e​/ and then by ​/l​/ in the word \"hello\". Each phoneme can in turn be\nconsidered as a particular random process (possibly Gaussian). This\nstructure can be adequately modeled by a left-right HMM.<br />\nIn \"real world\" speech recognition, the phonemes themselves are often\nmodeled as left-right HMMs rather than plain Gaussian densities\n(e.g. to model separately the beginning, then the stable middle part of\nthe phoneme and finally the end of it). Words are then represented by\nlarge HMMs made of concatenations of smaller phonetic HMMs.</li>\n</ol>\n\n</div>\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Pattern recognition with HMMs\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Likelihood of an observation sequence given a HMM\n\n"]},{"cell_type":"markdown","metadata":{},"source":["In the previous section, we have generated some stochastic observation sequences\nfrom various HMMs. Now, it is useful to study the reverse problem,\nnamely: given a new observation sequence and a set of models, which\nmodel explains best the sequence, or in other terms which model gives\nthe highest likelihood to the data?\n\nTo solve this problem, it is necessary to compute $p(X|\\Theta)$,\ni.e. the likelihood of an observation sequence given a model.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Probability of a state sequence $Q$\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The probability of a state sequence $Q=\\{q_1,\\cdots,q_T\\}$ coming from a\nHMM with parameters $\\Theta$ corresponds to the product of the\ntransition probabilities from one state to the following:\n\n$$\nP(Q|\\Theta) = \\prod_{t=1}^{T-1} a_{t,t+1}\n= a_{1,2} \\cdot a_{2,3} \\cdots a_{T-1,T}\n$$\n\n\nIn practice we will do the computations in log space to avoid numerical\nunderflow:\n\n$$\n\\log P(Q|\\Theta) = \\sum_{t=1}^{T-1} \\log a_{t,t+1}\n= \\log a_{1,2} + \\log a_{2,3} \\cdots \\log a_{T-1,T}\n$$\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["hmm = hmm3\nX, states, labels = hmm.sample()\nprint(\"States:\", states)\n\nfrom_states = states[:-1]  # Row indices into hmm3.transitions\nto_states = states[1:]     # Column indices\nlog_a = hmm.log_transitions[from_states, to_states]\nprint(\"Transition log probs:\", log_a)\n\nlog_P_Q = sum(log_a)\nprint(\"log P(Q):\", log_P_Q)"]},{"cell_type":"markdown","metadata":{},"source":["#### Likelihood of an observation sequence $X$ given a path $Q$\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Given an observation sequence $X=\\{x_1,x_2,\\cdots,x_T\\}$ and a state\nsequence $Q=\\{q_1,\\cdots,q_T\\}$ (of the same length) determined from a\nHMM with parameters $\\Theta$, the likelihood of $X$ along the path $Q$\nis equal to:\n\n$$\np(X|Q,\\Theta) = \\prod_{i=1}^T p(x_i|q_i,\\Theta)\n= b_1(x_1) \\cdot b_2(x_2) \\cdots b_T(x_T)\n$$\n\n\ni.e. it is the product of the emission probabilities computed along\nthe considered path.\n\nIn the previous lab, we had learned how to compute the likelihood of a\nsingle observation with respect to a Gaussian model. This method can be\napplied here, for each term $x_i$, if the states contain Gaussian pdfs.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["log_p_X_given_Q = sum(np.log(hmm.gaussians[state].pdf(x))\n                      for x, state in zip(X, states[1:-1]))\n\nprint(\"log p(X|Q):\", log_p_X_given_Q)"]},{"cell_type":"markdown","metadata":{},"source":["#### Joint likelihood of an observation sequence $X$ and a path $Q$\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The probability that $X$ and $Q$ occur simultaneously, $p(X,Q|\\Theta)$,\ndecomposes into a product of the two quantities defined previously:\n\n$$\np(X,Q|\\Theta) = p(X|Q,\\Theta) P(Q|\\Theta)\n$$\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["print(\"log p(X,Q):\", log_p_X_given_Q + log_P_Q)"]},{"cell_type":"markdown","metadata":{},"source":["#### Likelihood of observations with respect to a HMM\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The likelihood of an observation sequence $X=\\{x_1,x_2,\\cdots,x_T\\}$\nwith respect to a Hidden Markov Model with parameters $\\Theta$ expands\nas follows:\n\n$$\n    p(X|\\Theta) = \\sum_{every~possible~Q} p(X,Q|\\Theta)\n$$\n\n\ni.e. it is the sum of the joint likelihoods of the sequence over all\npossible state sequence allowed by the model.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### The Forward Algorithm\n\n"]},{"cell_type":"markdown","metadata":{},"source":["In practice, the enumeration of every possible state sequence is\ninfeasible even for small values of $N$ and $T$. Nevertheless,\n$p(X|\\Theta)$ can be computed in a recursive way (dynamic programming)\nby the **forward algorithm**. This algorithm defines a forward variable\n$\\alpha_t(i)$ corresponding to:\n\n$$\n    \\alpha_t(i) = p(x_1,x_2,\\cdots x_t,q^t=q_i|\\Theta)\n$$\n\n\ni.e. $\\alpha_t(i)$ is the probability of having observed the partial\nsequence $\\{x_1,x_2,\\cdots,x_t\\}$ *and* being in the state $i$ at time\n$t$ (event denoted $q_i^t$ in the course), given the parameters\n$\\Theta$. For a HMM with $N$ states (where states 1 and $N$ are the\nnon-emitting initial and final states, and states $2 \\cdots N-1$ are\nemitting), $\\alpha_t(i)$ can be computed recursively as follows:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["###### Initialization\n\n"]},{"cell_type":"markdown","metadata":{},"source":["$$\n        \\alpha_1(i) = a_{1,i} \\cdot b_i(x_1), \\;\\;\\;\\; 2 \\leq i \\leq N-1\n$$\n\nwhere $a_{1,i}$ are the transitions from the initial non-emitting state\nto the emitting states with pdfs $b_{i,\\,i = 2 \\cdots N-1}(x)$. Note\nthat $b_1(x)$ and $b_N{x}$ do not exist since they correspond to the\nnon-emitting initial and final states.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from idiap_spe.data.hmm import X1, X2, X3, X4, X5, X6\n\n# Let's pick a fixed sequence defined in `data.py` to make\n# the results reproducible\nhmm = hmm3\nX = X2\nprint(X)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# First precompute the b(x), i.e. pdfs, for all observations\n# and emitting states\nlog_bs = np.zeros((len(X), hmm.n_states))\nfor state in range(1, hmm.n_states - 1):\n    log_bs[:,state] = np.log(hmm.gaussians[state].pdf(X))\nprint(log_bs)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Then compute the initial alphas\nalphas = np.ones((len(X), hmm.n_states)) * -np.inf\nalphas[0] = hmm.log_transitions[0] + log_bs[0]\nprint(alphas)"]},{"cell_type":"markdown","metadata":{},"source":["###### Recursion\n\n"]},{"cell_type":"markdown","metadata":{},"source":["$$\n        \\alpha_{t+1}(j) = \\left[ \\sum_{i=2}^{N-1} \\alpha_{t}(i) \\cdot a_{i,j} \\right] b_j(x_{t+1}),\n        \\;\\;\\;\\; \\begin{array}{l} 1 \\leq t \\leq T \\\\ 2 \\leq j \\leq N-1 \\end{array}\n$$\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# We will show how to compute the alphas in 2 different ways\nalphas_2 = alphas.copy()\n\n# Basic Python way with 3 for-loops\nfor t in range(1, len(X)):\n    for j in range(1, hmm.n_states - 1):\n        log_as = -np.inf\n        for i in range(1, hmm.n_states - 1):\n            log_as = np.logaddexp(\n                log_as, alphas[t-1, i] + hmm.log_transitions[i, j])\n        alphas[t, j] = log_as + log_bs[t, j]\n\n# Remove the innermost loop thanks to Numpy\nfor t in range(1, len(X)):\n    for j in range(1, hmm.n_states - 1):\n        alphas_2[t, j] = np.logaddexp.reduce(\n            alphas_2[t-1] + hmm.log_transitions[:, j]) + log_bs[t, j]\n\n# Check that they are indeed the same\nprint(alphas)\nassert np.allclose(alphas, alphas_2)"]},{"cell_type":"markdown","metadata":{},"source":["###### Termination\n\n"]},{"cell_type":"markdown","metadata":{},"source":["$$\n        p(X|\\Theta) = \\left[ \\sum_{i=2}^{N-1} \\alpha_{T}(i) \\cdot a_{i,N} \\right]\n$$\n\ni.e. at the end of the observation sequence, sum the probabilities of\nthe paths converging to the final state $N$. (For more detail about the\nforward procedure, refer to Lawrence Rabiner's\n[Tutorial on Hidden Markov\nModels and Selected Applications in Speech Recognition](http://web.mit.edu/6.435/www/Rabiner89.pdf)).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["log_p_X = np.logaddexp.reduce(\n    alphas[-1] + hmm.log_transitions[:, hmm.n_states - 1])\nprint(\"p(X|hmm):\", log_p_X)"]},{"cell_type":"markdown","metadata":{},"source":["This procedure raises a very important implementation issue. As a matter\nof fact, the computation of the $\\alpha_t$ vector consists in products\nof a large number of values that are less than 1 (in general,\n*significantly* less than 1). Hence, after a few observations\n($t \\approx$ 10), the values of $\\alpha_t$ head exponentially to 0, and\nthe floating point arithmetic precision is exceeded (even in the case of\ndouble precision arithmetics). Two solutions exist for that problem. One\nconsists in scaling the values and undo the scaling at the end of the\nprocedure: see Rabiner's tutorial for more explanations. The other\nsolution consists in using log-likelihoods and log-probabilities, and to\ncompute $\\log p(X|\\Theta)$ instead of $p(X|\\Theta)$.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Questions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  The following formula can be used to compute the log of a sum given\n    the logs of the sum's arguments:\n    \n    $$\n       \\log(a+b) = f(\\log a,\\log b) = \\log a + \\log \\left( 1 + e^{(\\log b - \\log a)} \\right)\n       $$\n    \n    Prove its validity.\n    \n    Naturally, one has the choice between using\n    $\\log(a+b) = \\log a + \\log \\left( 1 + e^{(\\log b - \\log a)} \\right)$\n    or\n    $\\log(a+b) = \\log b + \\log \\left( 1 + e^{(\\log a - \\log b)} \\right)$,\n    which are equivalent in theory. If $\\log a > \\log b$, which version\n    leads to the most precise implementation?\n\n2.  Express the log version of the forward recursion. (Don't fully\n    develop the log of the sum in the recursion step, just call it\n    \"logsum\":\n    $\\sum_{i=1}^{N} x_i \\stackrel{\\log}{\\longmapsto} \\mbox{logsum}_{i=1}^{N} ( \\log x_i )$.)\n    In addition to the arithmetic precision issues, what are the other\n    computational advantages of the log version?\n\n"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":"true"},"source":["#### Answers\n\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"answer\" id=\"org2557b91\">\n<ol class=\"org-ol\">\n<li><p>\nProof:\n</p>\n\n<p>\n$$\n   a = e^{\\log a} \\;\\;\\;\\;\\;;\\;\\;\\;\\;\\; b = e^{\\log b}\n   $$\n</p>\n\n\\begin{align*}\na+b &= e^{\\log a} + e^{\\log b} \\\\\n    &= e^{\\log a} \\left( 1 + e^{(\\log b - \\log a)} \\right)\n\\end{align*}\n\n<p>\n$$\n   \\log(a+b) = \\log a + \\log \\left( 1 + e^{(\\log b - \\log a)} \\right) \\;\\;\\; \\square\n   $$\n</p>\n\n<p>\nThe computation of the exponential overflows the double precision\narithmetics for big values ($\\approx700$) earlier than for small\nvalues. Similarly, the implementations of the exponential operation\nare generally more precise for small values than for big values\n(since an error on the input term is exponentially amplified). Hence,\nif $\\log a > \\log b$, the first version\n($\\log(a+b) = \\log a + \\log \\left( 1 + e^{(\\log b - \\log a)} \\right)$)\nis more precise since in this case $(\\log b - \\log a)$ is small. If\n$\\log a < \\log b$, it is better to swap the terms (i.e. to use the\nsecond version). In practice, you would use an existing\nimplementation that handles this automatically, like\n<code>np.logaddexp()</code>.\n</p></li>\n\n<li><ul class=\"org-ul\">\n<li>Initialization\n$$\n       \\alpha_1^{(log)}(i) = \\log a_{1,i} + \\log b_i(x_1), \\;\\;\\;\\; 2 \\leq i \\leq N-1\n     $$</li>\n<li>Recursion\n$$\n       \\alpha_{t+1}^{(log)}(j) = \\left[ \\mbox{logsum}_{i=2}^{N-1} \\left(\n                           \\alpha_{t}^{(log)}(i) + \\log a_{i,j}\n                       \\right) \\right] + \\log b_j(x_{t+1}),\n       \\;\\;\\;\\; \\begin{array}{l} 1 \\leq t \\leq T \\\\ 2 \\leq j \\leq N-1 \\end{array}\n     $$</li>\n<li>Termination\n$$\n       \\log p(X|\\Theta) = \\left[ \\mbox{logsum}_{i=2}^{N-1} \\left(\n           \\alpha_{T}^{(log)}(i) + \\log a_{i,N} \\right) \\right]\n     $$\nIn addition to the precision issues, this version transforms the\nproducts into sums, which is more computationally efficient.\nFurthermore, if the emission probabilities are Gaussians, the\ncomputation of the log-likelihoods $\\log(b_j(x_t))$ eliminates the\ncomputation of the Gaussians' exponential (see the previous lab).</li>\n</ul></li>\n</ol>\n\n<p>\nThese two points show that once the theoretic barrier is crossed in the\nstudy of a particular statistical model, the importance of the\nimplementation issues must not be neglected.\n</p>\n\n</div>\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Bayesian classification\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Question\n\n"]},{"cell_type":"markdown","metadata":{},"source":["The forward recursion allows us to compute the likelihood of an\nobservation sequence with respect to a HMM. Hence, given a sequence of\nfeatures, we are able to find the most likely generative model in a\nMaximum Likelihood sense. What additional quantities and assumptions do\nwe need to perform a true Bayesian classification rather than a Maximum\nLikelihood classification of the sequences?\n\nWhich additional condition makes the result of Bayesian classification\nequivalent to the result of ML classification?\n\n"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":"true"},"source":["#### Answer\n\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"answer\" id=\"orgffdb56b\">\n<p>\nTo perform a Bayesian classification, we need the prior probabilities\n$P(\\Theta_i|\\Theta)$ of each model. In addition, we can assume that all\nthe observation sequences are equi-probable:\n</p>\n\n\\begin{align*}\nP(\\Theta_i|X,\\Theta) &= \\frac{p(X|\\Theta_i,\\Theta)\n                    P(\\Theta_i|\\Theta)}{P(X|\\Theta)}\\\\\n &\\propto p(X|\\Theta_i) P(\\Theta_i)\n\\end{align*}\n\n<p>\n$P(\\Theta_i)$ can be determined by counting the\nprobability of occurrence of each model (word or phoneme) in a database\ncovering the vocabulary to recognize (see the previous lab).\n</p>\n\n<p>\nIf every model has the same prior probability, then Bayesian\nclassification becomes equivalent to ML classification.\n</p>\n\n</div>\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Maximum Likelihood classification\n\n"]},{"cell_type":"markdown","metadata":{},"source":["In practice, for speech recognition, it is very often assumed that all\nthe model priors are equal (i.e. that the words or phonemes to recognize\nhave equal probabilities of occurring in the observed speech). Hence,\nthe speech recognition task consists mostly in performing the Maximum\nLikelihood classification of acoustic feature sequences. For that\npurpose, we must have of a set of HMMs that model the acoustic sequences\ncorresponding to a set of phonemes or a set of words. These models can\nbe considered as \"stochastic templates\". Then, we associate a new\nsequence to the most likely generative model. This part is called the\n**decoding** of the acoustic feature sequences.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Experiment\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Classify the sequences `X1`, `X2`, &#x2026;, `X6`, given in the file\n`data.py`, in a maximum likelihood sense with respect to the six Markov\nmodels defined above. Use the method `HMM.forward(X)` to compute the\nlog-forward recursion expressed in the previous section. Store the\nresults in the array `log_prob` (they will be used in the next section)\nand note them in the table below.\n\n\n| Sequence|$\\log p(X\\vert\\Theta_1)$|$\\log p(X\\vert\\Theta_2)$|$\\log p(X\\vert\\Theta_3)$|$\\log p(X\\vert  \\Theta_4)$|$\\log p(X\\vert  \\Theta_5)$|$\\log p(X\\vert  \\Theta_6)$|Most likely model|\n|---|---|---|---|---|---|---|---|\n| $X1$||||||||\n| $X2$||||||||\n| $X3$||||||||\n| $X4$||||||||\n| $X5$||||||||\n| $X6$||||||||\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["hmm1.plot_sample(X1)\nhmm1.forward(X1)"]},{"cell_type":"markdown","metadata":{},"source":["Filling the `log_prob` array can be done automatically with the help of\nloops:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["log_prob = np.zeros((6, 6))\nfor i, X in enumerate([X1, X2, X3, X4, X5, X6]):\n    for j, hmm in enumerate([hmm1, hmm2, hmm3, hmm4, hmm5, hmm6]):\n        log_prob[i, j] = hmm.forward(X)\n\nprint(log_prob.round(2))"]},{"cell_type":"markdown","metadata":{},"source":["## Optimal state sequence\n\n"]},{"cell_type":"markdown","metadata":{},"source":["In speech recognition and several other pattern recognition\napplications, it is useful to associate an \"optimal\" sequence of states\nto a sequence of observations, given the parameters of a model. For\ninstance, in the case of speech recognition, knowing which frames of\nfeatures \"belong\" to which state allows to locate the word boundaries\nacross time. This is called the *alignment* of acoustic feature\nsequences.\n\nA \"reasonable\" optimality criterion consists in choosing the state\nsequence (or *path*) that has the maximum likelihood with respect to a\ngiven model. This sequence can be determined recursively via the\n**Viterbi algorithm**. This algorithm makes use of two variables:\n\n-   The *highest* likelihood $\\delta_t(i)$ along a *single* path among\n    all the paths ending in state $i$ at time $t$:\n\n$$\n\\delta_t(i) = \\max_{q_1,q_2,\\cdots,q_{t-1}}\np(q_1,q_2,\\cdots,q_{t-1},q^t=q_i,x_1,x_2,\\cdots x_t|\\Theta)\n$$\n\n-   A variable $\\psi_t(i)$ which allows to keep track of the \"best path\"\n    ending in state $i$ at time $t$:\n\n$$\n\\psi_t(i) = \\mbox{arg}\\max_{\\hspace{-4.5ex}q_1,q_2,\\cdots,q_{t-1}}\np(q_1,q_2,\\cdots,q_{t-1},q^t=q_i,x_1,x_2,\\cdots x_t|\\Theta)\n$$\n\nNote that these variables are vectors of $(N-2)$ elements, $(N-2)$ being\nthe number of emitting states. With the help of these variables, the\nalgorithm takes the following steps:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Viterbi Algorithm\n\n"]},{"cell_type":"markdown","metadata":{},"source":["###### Initialization\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\\begin{align*}\n    \\delta_1(i) &= a_{1,i} \\cdot b_i(x_1), \\;\\;\\;\\; 2 \\leq i \\leq N-1 \\\\\n    \\psi_1(i) &= 0\n\\end{align*}\n\nwhere, again, $a_{1,i}$ are the transitions from the initial non-emitting\nstate to the emitting states with pdfs $b_{i,\\,i = 2 \\cdots N-1}(x)$,\nand where $b_1(x)$ and $b_N{x}$ do not exist since they correspond to\nthe non-emitting initial and final states.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["hmm = hmm3\nX = X2\n\n# First precompute the b(x), i.e. pdfs, for all observations\n# and emitting states\nlog_bs = np.zeros((len(X), hmm.n_states))\nfor state in range(1, hmm.n_states - 1):\n    log_bs[:,state] = np.log(hmm.gaussians[state].pdf(X))\nprint(log_bs)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Compute the initial deltas\ndeltas = np.ones((len(X), hmm.n_states)) * -np.inf\ndeltas[0] = hmm.log_transitions[0] + log_bs[0]\nprint(deltas)\n\n# Initialize the backpointers\npointers = np.zeros((len(X), hmm.n_states), dtype=int)\nprint(pointers)"]},{"cell_type":"markdown","metadata":{},"source":["###### Recursion\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\\begin{align*}\n        \\delta_{t+1}(j) &= \\max_{2 \\leq i \\leq N-1}\n            \\left[ \\delta_{t}(i) \\cdot a_{i,j} \\right]\n            \\cdot b_j(x_{t+1}),\n        \\;\\;\\;\\; \\begin{array}{l} 1 \\leq t \\leq T-1 \\\\ 2 \\leq j \\leq N-1 \\end{array}\n        \\\\\n        \\psi_{t+1}(j) &= \\mbox{arg}\\hspace{-0.5ex}\\max_{\\hspace{-3ex}2 \\leq i \\leq N-1}\n        \\left[ \\delta_{t}(i) \\cdot a_{i,j} \\right],\n        \\;\\;\\;\\; \\begin{array}{l} 1 \\leq t \\leq T-1 \\\\ 2 \\leq j \\leq N-1 \\end{array}\n\\end{align*}\n\n*Optimal policy is composed of optimal sub-policies*: find the path that\nleads to a maximum likelihood considering the best likelihood at the\nprevious step and the transitions from it; then multiply by the current\nlikelihood given the current state. Hence, the best path is found by\ninduction.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["for t in range(1, len(X)):\n    for j in range(1, hmm.n_states - 1):\n        deltas[t, j] = np.max(\n            deltas[t-1] + hmm.log_transitions[:, j]) + log_bs[t, j]\n        pointers[t, j] = np.argmax(\n            deltas[t-1] + hmm.log_transitions[:, j])\n\nprint(deltas)\nprint(pointers)"]},{"cell_type":"markdown","metadata":{},"source":["###### Termination\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\\begin{align*}\n        p^*(X|\\Theta) &= \\max_{2 \\leq i \\leq N-1}\n            \\left[ \\delta_{T}(i) \\cdot a_{i,N} \\right] \\\\\n        q_T^* &= \\mbox{arg}\\hspace{-0.5ex}\\max_{\\hspace{-3ex}2 \\leq i \\leq N-1}\n            \\left[ \\delta_{T}(i) \\cdot a_{i,N} \\right]\n\\end{align*}\n\nFind the best likelihood when the end of the observation sequence is\nreached, given that the final state is the non-emitting state $N$.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["log_p_vit_X = np.max(\n    deltas[-1] + hmm.log_transitions[:, hmm.n_states - 1])\nprint(\"p*(X|hmm):\", log_p_vit_X)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Determine from which state the final state was reached\npath = np.zeros((len(X)), dtype=int)\npath[-1] = np.argmax(\n    deltas[-1] + hmm.log_transitions[:, hmm.n_states - 1])\nprint(path)"]},{"cell_type":"markdown","metadata":{},"source":["###### Backtracking\n\n"]},{"cell_type":"markdown","metadata":{},"source":["$$\n        Q^* = \\{q_1^*,\\cdots,q_T^*\\} \\;\\;\\;\\;\\mbox{so that}\\;\\;\\;\\;\n        q_t^* = \\psi_{t+1}(q_{t+1}^*), \\;\\;\\;\\; t = T-1, T-2, \\cdots, 1\n$$\n\nRead (decode) the best sequence of states from the $\\psi_t$ vectors.\nRemember that $\\psi_t (j)$ stores the state from which we came if the\nbest sequence goes through state $j$ at time $t$. To get the path, we\ntherefore just need to follow the backpointers in reverse order.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["for t in range(len(X) - 2, -1, -1):\n    path[t] = pointers[t + 1, path[t + 1]]\n\nprint(path)"]},{"cell_type":"markdown","metadata":{},"source":["Additionally, the state sequence will always include the initial state\nat the beginning and the final state at the end.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Summary\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Hence, the Viterbi algorithm delivers *two* useful results, given an\nobservation sequence $X=\\{x_1,\\cdots,x_T\\}$ and a model $\\Theta$:\n\n-   The selection, among all the possible paths in the considered model, of the\n    *best path* $Q^* = \\{q^*_1,\\cdots,q^*_T\\}$, which corresponds to the\n    state sequence giving a maximum of likelihood to the observation\n    sequence $X$;\n-   The *likelihood along the best path*,\n    $p(X,Q^*|\\Theta) = p^*(X|\\Theta)$. As opposed to the the forward\n    procedure, where all the possible paths are considered, the Viterbi\n    computes a likelihood along the best path only.\n\n(For more detail about the Viterbi algorithm, refer to Lawrence\nRabiner's [Tutorial on\nHidden Markov Models and Selected Applications in Speech Recognition](http://web.mit.edu/6.435/www/Rabiner89.pdf)).\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Questions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["1.  From an algorithmic point of view, what is the main difference\n    between the computation of the $\\delta$ variable in the Viterbi\n    algorithm and that of the $\\alpha$ variable in the forward procedure?\n2.  Give the log version of the Viterbi algorithm.\n\n"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":"true"},"source":["#### Answers\n\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"answer\" id=\"orgcd16114\">\n<ol class=\"org-ol\">\n<li>The sums that were appearing in the computation of $\\alpha$ become\n$\\max$ operations in the computation of $\\delta$. Hence, the Viterbi\nalgorithm takes less computational power than the forward algorithm.</li>\n\n<li><ul class=\"org-ul\">\n<li><p>\nInitialization\n</p>\n\n\\begin{align*}\n  \\delta_1^{(log)}(i) &= \\log a_{1,i} + \\log b_i(x_1),\n  \\;\\;\\;\\; 2 \\leq i \\leq N-1 \\\\\n  \\psi_1(i) &= 0\n  \\end{align*}</li>\n<li><p>\nRecursion\n</p>\n\n\\begin{align*}\n  \\delta_{t+1}^{(log)}(j) &= \\max_{2 \\leq i \\leq N-1}\n      \\left[ \\delta_{t}^{(log)}(i) + \\log a_{i,j} \\right]\n       + \\log b_j(x_{t+1}),\n  \\;\\;\\;\\; \\begin{array}{l} 1 \\leq t \\leq T-1 \\\\ 2 \\leq j \\leq N-1 \\end{array}\\\\\n  \\psi_{t+1} &= \\mbox{arg}\\hspace{-0.5ex}\\max_{\\hspace{-3ex}2 \\leq i \\leq N-1}\n  \\left[ \\delta_{t}^{(log)}(i) + \\log a_{i,j} \\right],\n  \\;\\;\\;\\; \\begin{array}{l} 1 \\leq t \\leq T-1 \\\\ 2 \\leq j \\leq N-1 \\end{array}\n\\end{align*}</li>\n<li><p>\nTermination\n</p>\n\n\\begin{align*}\n  \\log p^*(X|\\Theta) &= \\max_{2 \\leq i \\leq N-1}\n      \\left[ \\delta_{T}^{(log)}(i) + \\log a_{i,N} \\right] \\\\\n  q_T^* &= \\mbox{arg}\\hspace{-0.5ex}\\max_{\\hspace{-3ex}2 \\leq i \\leq N-1}\n      \\left[ \\delta_{T}^{(log)}(i) + \\log a_{i,N} \\right]\n\\end{align*}</li>\n<li>Backtracking\n$$\n       Q^* = \\{q_1^*,\\cdots,q_T^*\\} \\;\\;\\;\\;\\mbox{so that}\\;\\;\\;\\;\n       q_t^* = \\psi_{t+1}(q_{t+1}^*) \\;\\;\\;\\; t = T-1, T-2, \\cdots, 1\n     $$</li>\n</ul></li>\n</ol>\n\n</div>\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Experiments\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Use the function `HMM.viterbi(X)` to find the best path of the\n    sequences $X_1, \\cdots X_6$ with respect to the most likely model\n    found with the forward algorithm (i.e. $X_1$: `hmm1`, $X_2$: `hmm3`, $X_3$: `hmm5`,\n    $X_4$: `hmm4`, $X_5$: `hmm6` and $X_6$: `hmm2`). Compare with the\n    state sequences $ST_1, \\cdots ST_6$ originally used to generate\n    $X_1, \\cdots X_6$ (use the function\n    `HMM.compare_sequences(X, S1, S2)`, which provides a view of the first\n    dimension of the observations as a time series, and allows to compare\n    the original alignment to the Viterbi solution).\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from idiap_spe.data.hmm import ST1, ST2, ST3, ST4, ST5, ST6\n\nbest_states, log_viterbi = hmm1.viterbi(X1)\nhmm1.compare_sequences(X1, ST1, best_states)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["best_states, log_viterbi = hmm3.viterbi(X2)\nhmm3.compare_sequences(X2, ST2, best_states)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["best_states, log_viterbi = hmm5.viterbi(X3)\nhmm5.compare_sequences(X3, ST3, best_states)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["best_states, log_viterbi = hmm4.viterbi(X4)\nhmm4.compare_sequences(X4, ST4, best_states)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["best_states, log_viterbi = hmm6.viterbi(X5)\nhmm6.compare_sequences(X5, ST5, best_states)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["best_states, log_viterbi = hmm2.viterbi(X6)\nhmm2.compare_sequences(X6, ST6, best_states)"]},{"cell_type":"markdown","metadata":{},"source":["-   Use the function `HMM.viterbi(X)` to compute the probabilities of the\n    sequences $X_1, \\cdots X_6$ along the best paths with respect to each\n    model $\\Theta_1, \\cdots \\Theta_6$. Note your results below. Compare\n    with the log-likelihoods obtained previously with the forward algorithm.\n\n\n| Sequence|$\\log p^*(X\\vert\\Theta_1)$|$\\log p^*(X\\vert\\Theta_2)$|$\\log p^*(X\\vert\\Theta_3)$|$\\log p^*(X\\vert\\Theta_4)$|$\\log p^*(X\\vert\\Theta_5)$|$\\log p^*(X\\vert\\Theta_6)$|Most likely model|\n|---|---|---|---|---|---|---|---|\n| $X1$||||||||\n| $X2$||||||||\n| $X3$||||||||\n| $X4$||||||||\n| $X5$||||||||\n| $X6$||||||||\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["log_viterbi = np.zeros((6, 6))\nfor i, X in enumerate([X1, X2, X3, X4, X5, X6]):\n    for j, hmm in enumerate([hmm1, hmm2, hmm3, hmm4, hmm5, hmm6]):\n        log_viterbi[i, j] = hmm.viterbi(X)[1]\n\nprint(log_viterbi.round(2))"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Comparison with the complete log-likelihoods from the forward algorithm\nprint((log_prob - log_viterbi).round(2))"]},{"cell_type":"markdown","metadata":{},"source":["#### Question\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Is the likelihood along the best path a good approximation of the real\nlikelihood of a sequence given a model ?\n\n"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":"true"},"source":["#### Answer\n\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"answer\" id=\"org25bc2a0\">\n<p>\nThe values found for both likelihoods differ within an acceptable error\nmargin. Furthermore, using the best path likelihood does not, in most\npractical cases, modify the classification results. Finally, it\nalleviates further the computational load since it replaces the sum or\nthe logsum by a max in the recursive part of the procedure. Hence, the\nlikelihood along the best path can be considered as a good approximation\nof the true likelihood.\n</p>\n\n</div>\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Training of HMMs\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Decoding or aligning acoustic feature sequences requires the prior\nspecification of the parameters of some HMMs. As explained before,\nthese models have the role of stochastic templates to which we compare\nthe observations. But how to determine templates that represent\nefficiently the phonemes or the words that we want to model? The\nsolution is to estimate the parameters of the HMMs from a database\ncontaining observation sequences, in a supervised or an unsupervised\nway.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Questions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["In the previous lab session, we have learned how to estimate the\nparameters of Gaussian pdfs given a set of training data. Suppose that\nyou have a database containing several utterances of the imaginary\nword / aiy / , and that you want to train a HMM for this word. Suppose also\nthat this database comes with a *labeling* of the data, i.e. some data\nstructures that tell you where are the phoneme boundaries for each\ninstance of the word.\n\n1.  Which model architecture (ergodic or left-right)\n    would you choose? With how many states? Justify your choice.\n2.  How would you compute the parameters of the proposed HMM?\n3.  Suppose you didn't have the phonetic labeling (i.e. you do\n    *unsupervised training*). Propose a recursive procedure to train\n    the model, making use of one of the algorithms studied during the\n    present session.\n\n"]},{"cell_type":"markdown","metadata":{"jp-MarkdownHeadingCollapsed":"true"},"source":["### Answers\n\n"]},{"cell_type":"markdown","metadata":{},"source":["<div class=\"answer\" id=\"org4c40230\">\n<ol class=\"org-ol\">\n<li>It can be assumed that the observation sequences associated with each\ndistinct phoneme obey specific densities of probability. As in the\nprevious lab, this means that the phonetic classes are assumed to be\nseparable by Gaussian classifiers. Hence, the word / aiy / can be\nassimilated to the result of drawing samples from the pdf\n${\\cal N}_{/a/}$, then transiting to ${\\cal N}_{/i/}$ and drawing\nsamples again, and finally transiting to ${\\cal N}_{/y/}$ and drawing\nsamples. It sounds therefore reasonable to model the word / aiy / by a\n<i>left-right</i> HMM with <i>three</i> emitting states.</li>\n<li>If we know the phonetic boundaries for each instance, we know to which\nstate belongs each training observation, and we can give a label (​/a​/,\n​/i​/ or ​/y​/) to each feature vector. Hence, we can use the mean and\nvariance estimators studied in the previous lab to compute the\nparameters of the Gaussian density associated with each state (or each\nlabel).<br />\nBy knowing the labels, we can also count the transitions from one\nstate to the following (itself or another state). By dividing the\ntransitions that start from a state by the total number of transitions\nfrom this state, we can determine the transition matrix.</li>\n<li><p>\nThe Viterbi procedure allows to distribute some labels on a sequence\nof features. Hence, it is possible to perform unsupervised training in\nthe following way:\n</p>\n\n<ol class=\"org-ol\">\n<li>Start with some arbitrary state sequences, which constitute an\ninitial labeling. (The initial sequences are usually made of even\ndistributions of phonetic labels along the length of each\nutterance.)</li>\n<li>Update the model, relying on the current labeling.</li>\n<li>Use the Viterbi algorithm to re-distribute some labels on the\ntraining examples.</li>\n<li>If the new distribution of labels differs from the previous one,\nre-iterate (go to (b) ). One can also stop when the evolution of\nthe likelihood of the training data becomes asymptotic to a higher\nbound.</li>\n</ol>\n\n<p>\nThe principle of this algorithm is similar to the Viterbi-EM, used to\ntrain the Gaussians during the previous lab. Similarly, there exists a\n\"soft\" version, called the <i>Baum-Welch</i> algorithm, where each state\nparticipates to the labeling of the feature frames (this version uses\nthe forward recursion instead of the Viterbi). The Baum-Welch\nalgorithm is an EM algorithm specifically adapted to the training of\nHMMs (see Lawrence Rabiner's\n[a href=\"http://web.mit.edu/6.435/www/Rabiner89.pdf\">Tutorial on Hidden\nMarkov Models and Selected Applications in Speech Recognition</a>](a href=\"http://web.mit.edu/6.435/www/Rabiner89.pdf\">Tutorial on Hidden\nMarkov Models and Selected Applications in Speech Recognition</a>)for\ndetails), and is one of the most widely used training algorithms in\n\"real world\" speech recognition.\n</p></li>\n</ol>\n\n</div>\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## Acknowledgements\n\n"]},{"cell_type":"markdown","metadata":{},"source":["This lab was originally developed by Sacha Krstulović, Hervé\nBourlard, Hemant Misra, and Mathew Magimai-Doss for the *Speech Processing and\nSpeech Recognition* course at École polytechnique fédérale de Lausanne (EPFL).\nThe original Matlab version is available here:\n[http://publications.idiap.ch/index.php/publications/show/739](http://publications.idiap.ch/index.php/publications/show/739)\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}
