{"cells":[{"cell_type":"markdown","metadata":{},"source":"Grapheme-to-Phoneme (G2P) Conversion with Phonetisaurus\n=======================================================\n\n"},{"cell_type":"markdown","metadata":{},"source":["## Introduction\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Both automatic speech recognition (ASR) and text-to-speech (TTS) systems usually\nrequire a lexicon that lists the pronunciations of words. However, a lexicon can\nnever cover all words. In this case, pronunciations are obtained from a\ngrapheme-to-phoneme (G2P), or letter-to-sound, model. [Phonetisaurus](https://github.com/AdolfVonKleist/Phonetisaurus) is a common\ntool to train G2P models. In this exercise we will train a G2P model on the [CMU\nlexicon](https://github.com/cmusphinx/cmudict) for American English and then use it to generate pronunciations for\nnew words. A wrapper for Phonetisaurus is available on [PyPI](https://pypi.org/project/phonetisaurus/) and can be used from\nPython as in this lab, but for the full functionality you should use the command\nline.\n\nThe goal of this lab is to get a better understanding of **what** G2P is, **why** it\nis needed for ASR and TTS, and **what data** you need for training a G2P model.\nYou don't have to worry about the details of **how** the model is trained, this is\nbeyond the scope of this course, but you should be able to think of some methods\nwhich you could use for this.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%load_ext autoreload\n%autoreload 2"]},{"cell_type":"markdown","metadata":{},"source":["## The CMU pronunciation lexicon\n\n"]},{"cell_type":"markdown","metadata":{},"source":["First let's read the CMU lexicon file into a Python dictionary, so that we can\ntake a look at what's inside. The `cmudict` [Python wrapper package](https://pypi.org/project/cmudict/) provides easy\naccess to the lexicon.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import cmudict\nimport phonetisaurus as ps\n\nlexicon = ps.load_lexicon(cmudict.dict_string().decode().split(\"\\n\"))"]},{"cell_type":"markdown","metadata":{},"source":["Look at a sample of words and their pronunciations to become familiar with the\nformat and notation:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import random\nfor word in random.sample(list(lexicon), 10):\n    print(word + \":\", \" \".join(lexicon[word][0]))"]},{"cell_type":"markdown","metadata":{},"source":["Note that words can have multiple possible pronunciations:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["lexicon[\"either\"]"]},{"cell_type":"markdown","metadata":{},"source":["## Training a G2P model\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Now we will train a G2P model. This should not take more than 5 minutes.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["help(ps.train)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["model_path = \"g2p.fst\"\nps.train(lexicon, model_path)"]},{"cell_type":"markdown","metadata":{},"source":["## Generating pronunciations\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Now we can generate pronunciations for new words with our model:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["help(ps.predict)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["words = [\"excellent\", \"eggselent\", \"otorhinolaryngological\"]\nfor prediction in ps.predict(words, model_path):\n    print(prediction)"]},{"cell_type":"markdown","metadata":{},"source":["Try out other words to see their predicted pronunciations, including\nmisspellings, your own name, foreign or other challenging words, etc. Remember,\nthe task of a G2P model is to predict pronunciations for rare words that are not\nfound in the lexicon.\n\nYou can also obtain multiple candidate pronunciations for each word:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["words = [\"eggselent\"]\nfor prediction in ps.predict(words, model_path, nbest=5):\n    print(prediction)"]},{"cell_type":"markdown","metadata":{},"source":["## How it works\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Phonetisaurus learns to align grapheme and phoneme sequences with the EM\nalgorithm to identify relationships such as *igh-​/AY​/*. It then trains an N-gram\nmodel on the aligned sequences and converts it to a weighted finite-state\ntransducer (WFST). It support multiple methods to obtain pronunciations for new\nwords from this WFST. You can find more information in the paper [WFST-Based\nGrapheme-to-Phoneme Conversion: Open Source tools for Alignment, Model-Building\nand Decoding](https://www.aclweb.org/anthology/W12-6208/).\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}
